---
title: "Self-Improving Teacher Cultivates Better Student: Distillation Calibration for Multimodal Large Language Models"
collection: publications
permalink: /publication/2024-05-13-paper-title-number-1
excerpt: 'This paper is about Reasoning on LLMs'
date: 2024-07-17
venue: 'SIGIR'
paperurl: # 'http://academicpages.github.io/files/paper1.pdf'
citation: 'Li Lin, Yixin Cao, Lifu Huang, Shu’Ang Li, Xuming Hu, Lijie Wen, and Jianmin Wang. 2022. What Makes the Story Forward? Inferring Commonsense Explanations as Prompts for Future Event Generation. In Proceedings of the 45th Int’l ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR ’22), July 11–15, 2022, Madrid, Spain. ACM, New York, NY, USA, 12 pages. https://doi.org/10.1145/3477495.3532080 '
---

Multimodal content generation, which leverages visual informa- tion to enhance the comprehension of cross-modal understanding, plays a critical role in Multimodal Information Retrieval. With the development of large language models (LLMs), recent research has adopted visual instruction tuning to inject the knowledge of LLMs into downstream multimodal tasks. The high complexity and great demand for resources urge researchers to study efficient distillation solutions to transfer the knowledge from pre-trained multimodal models (teachers) to more compact student models. However, the instruction tuning for knowledge distillation in multimodal LLMs is resource-intensive and capability-restricted. The comprehension of students is highly reliant on the teacher models. To address this issue, we propose a novel Multimodal Distillation Calibration framework (MmDC). The main idea is to generate high-quality training instances that challenge student models to comprehend and prompt the teacher to calibrate the knowledge transferred to students, ultimately cultivating a better student model in down- stream tasks. This framework comprises two stages: (1) multimodal alignment and (2) knowledge distillation calibration. In the first stage, parameter-efficient fine-tuning is used to enhance feature alignment between different modalities. In the second stage, we de- velop a calibration strategy to assess the student model’s capability and generate high-quality instances to calibrate knowledge distilla- tion from teacher to student. The experiments on diverse datasets show that our framework efficiently improves the student model’s capabilities. Our 7B-size student model, after three iterations of distillation calibration, outperforms the current state-of-the-art LLaVA-13B model on the ScienceQA and LLaVA Test datasets and also exceeds other strong baselines in a zero-shot setting.

